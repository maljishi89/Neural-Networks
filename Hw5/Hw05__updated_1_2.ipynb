{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hw05__updated_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzVHVHCVdYSD"
      },
      "source": [
        "# Predicting speech tags \n",
        "\n",
        "Refer: `Frame Level Classification of Speech.doc` for the problem description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wILkk5uNBlI"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import timeit"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-QyGa5P-aQU"
      },
      "source": [
        "# Path to home\n",
        "PATH = os.getcwd()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqh27OgnruMz",
        "outputId": "434ba2c0-2be7-4c1c-e93b-91e65bd8749d"
      },
      "source": [
        "# Check the work space is enabled  with GPU.\n",
        "import torch\n",
        "cuda = torch.cuda.is_available()\n",
        "print(cuda)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8lmTzMbraRv"
      },
      "source": [
        "data_folder = os.path.join(PATH, 'data')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEjF9hpryJYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12f65a1-3c8d-44b0-b6d6-4f662a99c65a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlGVGW6DraRv"
      },
      "source": [
        "train = np.load('/content/drive/My Drive/Colab Notebooks/ntrain.npy', allow_pickle=True)\n",
        "train_labels = np.load('/content/drive/My Drive/Colab Notebooks/ntrain_labels.npy', allow_pickle=True)\n",
        "\n",
        "dev = np.load('/content/drive/My Drive/Colab Notebooks/nval.npy', allow_pickle=True)\n",
        "dev_labels = np.load('/content/drive/My Drive/Colab Notebooks/nval_labels.npy', allow_pickle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LElAWzbvOQD2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "kpLctmADgRTY",
        "outputId": "6e299e55-a0c3-48f9-8791-494cdc38cf9c"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5e6a15ce28a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SxL-A66gX9o"
      },
      "source": [
        "# # Using subset of complete data when modifying\n",
        "\n",
        "# dev = dev[:20]\n",
        "# dev_labels = dev_labels[:20]\n",
        "# train = train[:10]\n",
        "# train_labels = train_labels[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnBp3-DuPZhY"
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "class TensorDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        super().__init__()\n",
        "        assert len(x) == len(y)\n",
        "        self._x = x\n",
        "        self._y = y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self._x)\n",
        "      \n",
        "    def __getitem__(self, index):\n",
        "        x_item = self._x[index]\n",
        "        return torch.FloatTensor(x_item), torch.FloatTensor(self._y[index])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0Dt1ficNvHa"
      },
      "source": [
        "train_dataset = TensorDataset(train, train_labels)\n",
        "\n",
        "load_train = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = 1,\n",
        "    shuffle=False,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "dev_dataset = TensorDataset(dev, dev_labels)\n",
        "\n",
        "load_valid = DataLoader(\n",
        "    dev_dataset,\n",
        "    batch_size = 1\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp-GXCSn2IaI"
      },
      "source": [
        "import torch\n",
        "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjOHGH1P2K84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1ac618-2a59-4e43-bfe5-abb76db82be6"
      },
      "source": [
        "# DEVICE = 'cpu'\n",
        "DEVICE"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPh7B8uOy6uM"
      },
      "source": [
        "embedding_dim = 13\n",
        "hidden_dim = 10\n",
        "vocab_size = 346 # [0-347]\n",
        "layers=4\n",
        "\n",
        "def hidden_init():\n",
        "    return (torch.rand(layers*2, 1, hidden_dim).to(DEVICE) ,\n",
        "            torch.rand(layers*2, 1, hidden_dim).to(DEVICE))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOUw8_7SwdTz"
      },
      "source": [
        "class LSTM_model(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(LSTM_model, self).__init__()\n",
        "        self.vocab_size = 346 #vocab_size change to 346 ????\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim, num_layers=layers, dropout = 0.2, bidirectional = True).to(DEVICE)\n",
        "        self.linear = torch.nn.Linear(hidden_dim*2, vocab_size)       # *2 applied if bidir = true\n",
        "        self.softmax = torch.nn.functional.softmax\n",
        "        \n",
        "    def forward(self, encrypted):\n",
        "        lstm_in = encrypted.transpose(0,1)\n",
        "\n",
        "        lstm_out, lstm_hidden = self.lstm(lstm_in.float(), hidden_init())\n",
        "        \n",
        "        scores = self.linear(lstm_out)\n",
        "        scores = scores.transpose(1, 2)\n",
        "\n",
        "        return scores\n",
        "\n",
        "model = LSTM_model(vocab_size, embedding_dim, hidden_dim)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "710wAAeIzIqw"
      },
      "source": [
        "model = model.to(DEVICE)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyqHMD_hrP6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a812637a-6c37-49bb-b1e6-e1fdac44de5f"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/trained_model_Hw5_2.pt', map_location=torch.device('cpu')))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ9KYuMJIJmq"
      },
      "source": [
        "# Printing validation loss at regular intervals\n",
        "validation_time = len(train) / 20"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wSFXyN0EUhY",
        "outputId": "e7decdce-5f75-418f-b6d4-626629f23dc2"
      },
      "source": [
        "print(validation_time)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "983.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3FjtLoQEU2l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYAGjY85fj9o"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zprCdaUN_hHZ"
      },
      "source": [
        "losses = []\n",
        "\n",
        "class LSTM_Trainer():\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.loss_fn = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001) \n",
        "\n",
        "    def get_loss(self, encrypted, original) :\n",
        "        encrypted = encrypted.to(DEVICE).long()\n",
        "        original = original.to(DEVICE).long()\n",
        "\n",
        "        scores = self.model.forward(encrypted)\n",
        "        original = original.transpose(0,1)\n",
        "        original = original.long()\n",
        "\n",
        "        loss = self.loss_fn(scores, original)  # <- Training loss\n",
        "        return loss\n",
        "\n",
        "    def train(self, num_epochs):\n",
        "        accuracies, max_accuracy = [], 0\n",
        "        best_valid_loss = 10   # V.high initialization\n",
        "\n",
        "        with open(os.path.join(PATH, 'history.csv'),'w') as writer:\n",
        "            for N in range(num_epochs):\n",
        "                start_save_time = time.monotonic()\n",
        "                print('Epoch: {}'.format(N))\n",
        "                for i, (encrypted, original) in enumerate(load_train):  #dataset(num_examples):\n",
        "                    self.optimizer.zero_grad()\n",
        "  \n",
        "                    loss = self.get_loss(encrypted, original)  # <- Training loss\n",
        "                    loss.backward()\n",
        "\n",
        "                    self.optimizer.step()\n",
        "\n",
        "                # Validation\n",
        "                    if i % validation_time == 0:\n",
        "\n",
        "                        print('Validation:' + str(i))\n",
        "                        validation_loss = []\n",
        "                        for (val_encrypted, val_original) in load_valid:    #val dataset(num_examples):\n",
        "                            val_loss = self.get_loss(val_encrypted, val_original) \n",
        "                      \n",
        "                            validation_loss.append(val_loss.item())\n",
        "\n",
        "                        avg_loss = sum(validation_loss) / len(validation_loss)\n",
        "                        print('Training Loss: {:6.4f}'.format(loss.item()))\n",
        "                        print('Validation Loss: {:6.4f}'.format(avg_loss))        \n",
        "                        writer.write(str(N)+','+str(i)+','+str(loss.item())+','+str(avg_loss))\n",
        "                        writer.write('\\n')\n",
        "\n",
        "                # Saving the model after an epoch\n",
        "                model_saved = os.path.join(PATH, 'model_' + str(N+1) + '.sav')\n",
        "                torch.save(self.model.state_dict(), '/content/drive/My Drive/Colab Notebooks/trained_model_Hw5_0.pt')\n",
        "                torch.save(self.model.state_dict(), model_saved)\n",
        "                print('Train Loss at end of epoch: {:6.4f}'.format(loss.item()))\n",
        "                end_save_time = time.monotonic()\n",
        "                save_min, save_sec = epoch_time(start_save_time, end_save_time)\n",
        "                print(f'Epoch: {N+1:02} | Epoch Time: {save_min}m {save_sec}s\\n')\n",
        "                print(\"\\n----------------------------------------------------------------------\\n\");"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gQ6UyAyA9n8"
      },
      "source": [
        "trainer = LSTM_Trainer(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3jrzQuDA6u2"
      },
      "source": [
        "Working on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6n_Tw_CraRw"
      },
      "source": [
        "n_epochs = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "GqhfDYHBA9dt",
        "outputId": "9635f8ba-4f44-4e30-fb8c-435136c836e0"
      },
      "source": [
        "# Below call starts training models for required epochs\n",
        "\n",
        "trainer.train(n_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-15d163f90819>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Below call starts training models for required epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-0bebb2449faa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mstart_save_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencrypted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#dataset(num_examples):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1516, 13] at entry 0 and [1429, 13] at entry 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yN1CSxEsmsC"
      },
      "source": [
        "# torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/trained_model/trained_model_Hw5_0.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66g60HIF-8UD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_1Ii4DgraRw"
      },
      "source": [
        "The above module will train the output `model` using which the below predictions on test will be carried out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKsgYML-OXie"
      },
      "source": [
        "ntest = np.load('/content/drive/My Drive/Colab Notebooks/ntest.npy',allow_pickle=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBjpfRuCraRw"
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, x):\n",
        "        super().__init__()\n",
        "        # assert len(x) == len(y)\n",
        "        self._x = x\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self._x)\n",
        "      \n",
        "    def __getitem__(self, index):\n",
        "        x_item = self._x[index]\n",
        "        return torch.FloatTensor(np.array(x_item))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACrZfJUcraRw"
      },
      "source": [
        "test = np.load(os.path.join(data_folder, '/content/drive/My Drive/Colab Notebooks/ntest.npy'), allow_pickle=True)\n",
        "\n",
        "test_dataset = TestDataset(ntest)\n",
        "\n",
        "load_test = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = 1,\n",
        "    shuffle=False,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsFIrtdp-agi"
      },
      "source": [
        "def test_model(model, test_loader):\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    pred = []\n",
        "\n",
        "    for batch_idx, (data) in enumerate(test_loader):   \n",
        "      data = data.to(DEVICE)\n",
        "      outputs = model(data)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      pred.append(predicted.cpu().numpy()[0])\n",
        "\n",
        "    return np.array(pred)\n",
        "\n",
        "pred = test_model(model, load_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXWszLX3uzmo"
      },
      "source": [
        "soft = torch.nn.Softmax(dim=0)\n",
        "\n",
        "with open('/content/drive/My Drive/Colab Notebooks/hw1_submission.csv', 'w') as output:\n",
        "    output.write('id,label')\n",
        "    output_id = 0\n",
        "    for encrypted in load_test:\n",
        "        \n",
        "        scores = model.forward(encrypted)\n",
        "\n",
        "        soft_scores = soft(scores[0])      \n",
        "        predictions = torch.max(soft_scores, 0)   \n",
        "        for prediction in predictions:\n",
        "            output.write(f\"{output_id},{prediction}\")\n",
        "            output_id += 1\n",
        "        #(output_id + ',' + prediction)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpAAeTuFkTC3"
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/labelssssssss.csv', 'w') as w:\r\n",
        "    w.write('id,label\\n')\r\n",
        "    for i in range(len(pred)):\r\n",
        "            w.write(str(i)+','+str(pred[i])+'\\n')"
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}