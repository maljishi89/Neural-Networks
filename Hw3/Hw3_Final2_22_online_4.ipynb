{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Hw3_Final2_22_online_4.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7brb68JUYTZ7","executionInfo":{"status":"ok","timestamp":1604501956297,"user_tz":-180,"elapsed":1233,"user":{"displayName":"M M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTpe2wb6eeAb5oACw2uQos9tk5KOT_ogG8zrvJog=s64","userId":"00095342535920509079"}},"outputId":"9fb0c6cb-60c1-4c94-ebf9-f1bbda4fb656","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install adabelief-pytorch==0.1.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: adabelief-pytorch==0.1.0 in c:\\users\\malji\\anaconda3\\lib\\site-packages (0.1.0)\n","Requirement already satisfied: tabulate>=0.7 in c:\\users\\malji\\anaconda3\\lib\\site-packages (from adabelief-pytorch==0.1.0) (0.8.7)\n","Requirement already satisfied: torch>=0.4.0 in c:\\users\\malji\\anaconda3\\lib\\site-packages (from adabelief-pytorch==0.1.0) (1.6.0)\n","Requirement already satisfied: colorama>=0.4.0 in c:\\users\\malji\\anaconda3\\lib\\site-packages (from adabelief-pytorch==0.1.0) (0.4.3)\n","Requirement already satisfied: future in c:\\users\\malji\\anaconda3\\lib\\site-packages (from torch>=0.4.0->adabelief-pytorch==0.1.0) (0.18.2)\n","Requirement already satisfied: numpy in c:\\users\\malji\\anaconda3\\lib\\site-packages (from torch>=0.4.0->adabelief-pytorch==0.1.0) (1.18.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FmCYkAEGJF9o"},"source":["import time\n","import torch\n","import timeit\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","from adabelief_pytorch import AdaBelief\n","from torch.utils import data\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","from collections import namedtuple\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, datasets, models\n","from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n","\n","%matplotlib inline\n","np.random.seed(2018)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fctKZgYCz1N"},"source":["train = np.load('C:/Users/malji/Google Drive/Colab Notebooks/Hw3/ntrain.npy',allow_pickle=True)\n","train_labels = np.load('C:/Users/malji/Google Drive/Colab Notebooks/Hw3/ntrain_labels.npy',allow_pickle=True)\n","val = np.load('C:/Users/malji/Google Drive/Colab Notebooks/Hw3/nval.npy',allow_pickle=True)\n","val_labels = np.load('C:/Users/malji/Google Drive/Colab Notebooks/Hw3/nval_labels.npy',allow_pickle=True)\n","ntest = np.load('C:/Users/malji/Google Drive/Colab Notebooks/Hw3/ntest.npy',allow_pickle=True)\n","phones = np.loadtxt(\"C:/Users/malji/Google Drive/Colab Notebooks/Hw3/phones.txt\", dtype=str)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzCN4uGAADHw"},"source":["class PhonesDataset(Dataset):\n","  def __init__(self, x,y,k):             \n","    self.x = x\n","    self.y = y\n","    self.k = k\n","    self.inputs = []\n","    self.lab = np.array([])\n","    self.idx = []\n","    self._init_dataset()\n","      \n","  def __len__(self):\n","    return len(self.lab)\n","\n","  def __getitem__(self,index):\n","    i = self.idx[index]\n","    return torch.from_numpy(np.concatenate(self.inputs[i-self.k:i+self.k+1],axis=0)).float(),torch.tensor(self.lab[index]).long()\n","  \n","  def _init_dataset(self):\n","    idx=0\n","    for i in range(len(self.x)):\n","      start_time = time.time()#######\n","      s = len(self.x[i])\n","      x=np.pad(self.x[i],((self.k, self.k), (0, 0)), 'constant', constant_values=0)\n","\n","      idx += 2*self.k\n","      for j in range(s):           \n","        self.idx+=[idx-self.k]\n","        idx += 1\n","\n","      self.inputs+=list(x)  \n","      self.lab = np.append(self.lab,self.y[i])\n","      end_time = time.time()#######  \n","    return np.array(self.inputs), self.lab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NCCxmr1eHu94"},"source":["class TestDataset(Dataset):\n","  def __init__(self, x,k):       \n","    self.x = x\n","    self.k = k\n","    self.inputs = []\n","    self.idx = []\n","    self._init_dataset()\n","      \n","  def __len__(self):\n","    return len(self.idx)\n","\n","  def __getitem__(self,index):\n","    idx = self.idx[index]\n","    return torch.from_numpy(np.concatenate(self.inputs[idx-self.k:idx+self.k+1],axis=0)).float()\n","  \n","  def _init_dataset(self):\n","    idx=0\n","    for i in range(len(self.x)):\n","      start_time = time.time()#######\n","      s = len(self.x[i])\n","      x=np.pad(self.x[i],((self.k, self.k), (0, 0)), 'constant', constant_values=0)\n","\n","      idx += 2*self.k\n","      for j in range(s):           \n","        self.idx+=[idx-self.k]\n","        idx += 1\n","\n","      self.inputs+=list(x)  \n","      end_time = time.time()#######\n","      if i==1000:##########\n","        print('Time: ',end_time - start_time, 's') #######    \n","    return np.array(self.inputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0IOIUfLz1i8A"},"source":["# def save_data(loader):\n","#     print('saving data...')\n","    \n","#     for i, (x, y) in enumerate(loader):\n","        \n","#         x=x.view(-1, 13).numpy()\n","#         y = y.numpy()\n","#         if i==0:\n","#             data = np.array(x)\n","#             label = np.array(y)\n","#         else:     \n","#             data = np.concatenate((data, x))\n","#             label = np.concatenate((label, y))\n","#     return data, label\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3CtnjHS51WjP"},"source":["# #saving datas\n","# start_time = time.time()\n","# print(\"saving data...\")\n","# data, labels = save_data(train_loader)\n","# np.save('C:/Users/malji/Google Drive/Colab Notebooks/Hw3/train_data_new.npy', data)\n","# np.save('C:/Users/malji/Google Drive/Colab Notebooks/Hw3/train_labels_new.npy', labels)\n","# print(\"train data savied in:\")\n","# print(\"--- %s seconds ---\" % (time.time() - start_time))\n","# print(\"\\n===================================\\n\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XAf57CUJrXnG","executionInfo":{"status":"ok","timestamp":1604502771769,"user_tz":-180,"elapsed":816671,"user":{"displayName":"M M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTpe2wb6eeAb5oACw2uQos9tk5KOT_ogG8zrvJog=s64","userId":"00095342535920509079"}},"outputId":"613c5a18-8dee-478e-c19a-b29f5e43ab66","colab":{"base_uri":"https://localhost:8080/"}},"source":["cuda = torch.cuda.is_available()\n","num_workers = 0 #8 if cuda else 0 \n","    \n","# Training\n","start_time = time.time()\n","train_dataset = PhonesDataset(train, train_labels,50)\n","train_loader_args = dict(shuffle=True, batch_size=256, num_workers=num_workers, pin_memory=True)\n","train_loader = data.DataLoader(train_dataset, **train_loader_args)\n","print(\"taken time: %s seconds ---\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["taken time: 812.9333379268646 seconds ---\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7sllfklfp5Lb","executionInfo":{"status":"ok","timestamp":1604502779088,"user_tz":-180,"elapsed":823983,"user":{"displayName":"M M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTpe2wb6eeAb5oACw2uQos9tk5KOT_ogG8zrvJog=s64","userId":"00095342535920509079"}},"outputId":"1e14d41a-9992-4a70-cb81-052ec892d78c","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Validation\n","start_time = time.time()\n","num_workers = 0 #8 \n","val_dataset = PhonesDataset(val, val_labels,50)\n","val_loader_args = dict(shuffle=False, batch_size=256, num_workers=num_workers, pin_memory=True)\n","val_loader = data.DataLoader(val_dataset, **val_loader_args)\n","print(\"taken time: %s seconds ---\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["taken time: 7.3186492919921875 seconds ---\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mH8_GKXRrXyy","executionInfo":{"status":"ok","timestamp":1604502781192,"user_tz":-180,"elapsed":826081,"user":{"displayName":"M M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTpe2wb6eeAb5oACw2uQos9tk5KOT_ogG8zrvJog=s64","userId":"00095342535920509079"}},"outputId":"c71bff09-564c-43be-8165-6989f1e12a90","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Testing\n","start_time = time.time()\n","test_dataset = TestDataset(ntest,50)\n","test_loader_args = dict(shuffle=False, batch_size=1, num_workers=num_workers, pin_memory=True)\n","test_loader = data.DataLoader(test_dataset, **test_loader_args)\n","print(\"taken time: %s seconds ---\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Time:  0.0 s\n","taken time: 2.0988807678222656 seconds ---\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tdDMVQRsjn8g"},"source":["def init_xavier(m):\n","  if type(m) == nn.Linear:\n","    fan_in = m.weight.size()[1]\n","    fan_out = m.weight.size()[0]\n","    std = np.sqrt(1.0/(fan_in + fan_out))\n","    m.weight.data.normal_(0,std)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mAz8hhEifIP"},"source":["def init_hey(m):\n","  if type(m) == nn.Linear:\n","    fan_in = m.weight.size()[1]\n","    fan_out = m.weight.size()[0]\n","    std = np.sqrt(2.0/(fan_in + fan_out))\n","    m.weight.data.normal_(0,std)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E_6C6BRmz7Li"},"source":["class PhonesModel(nn.Module):\n","  # try changing 32 to 128\n","  def __init__(self):\n","    super(PhonesModel, self).__init__()\n","    self.fc1 = nn.Linear(1313, 4096 )\n","    self.bnorm1 = nn.BatchNorm1d(4096 )\n","    self.dp1 = nn.Dropout(p=0.1)\n","    self.fc2 = nn.Linear(4096, 2048 )\n","    self.bnorm2 = nn.BatchNorm1d(2048 )\n","    self.dp2 = nn.Dropout(p=0.1)\n","    self.fc3 = nn.Linear(2048, 1024 )\n","    self.bnorm3 = nn.BatchNorm1d(1024 )\n","    self.dp3 = nn.Dropout(p=0.1)\n","    self.fc4 = nn.Linear(1024 , 1024 )\n","    self.bnorm4 = nn.BatchNorm1d(1024 )\n","    self.dp4 = nn.Dropout(p=0.1)\n","    self.fc5 = nn.Linear(1024, 512 )\n","    self.bnorm5 = nn.BatchNorm1d(512 )\n","    self.dp5 = nn.Dropout(p=0.1)\n","    self.fc6 = nn.Linear(512, 256 )\n","    self.bnorm6 = nn.BatchNorm1d(256 )\n","    self.dp6 = nn.Dropout(p=0.1)\n","    self.fc7 = nn.Linear(256 , 346)\n","  \n","  def forward(self, x):\n","    x = F.relu(self.fc1(x))\n","    x = self.dp1(self.bnorm1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.dp2(self.bnorm2(x))\n","    x = F.relu(self.fc3(x))\n","    x = self.dp3(self.bnorm3(x))\n","    x = F.relu(self.fc4(x))\n","    x = self.dp4(self.bnorm4(x))\n","    x = F.relu(self.fc5(x))\n","    x = self.dp5(self.bnorm5(x))\n","    x = F.relu(self.fc6(x))\n","    x = self.dp6(self.bnorm6(x))\n","    x = F.log_softmax(self.fc7(x))\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ExIq4HAuz_vt","executionInfo":{"status":"ok","timestamp":1604502784771,"user_tz":-180,"elapsed":829644,"user":{"displayName":"M M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTpe2wb6eeAb5oACw2uQos9tk5KOT_ogG8zrvJog=s64","userId":"00095342535920509079"}},"outputId":"6368b252-df01-4258-fc88-d55d12f32001","colab":{"base_uri":"https://localhost:8080/"}},"source":["model = PhonesModel()\n","model.apply(init_xavier)\n","criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.Adam(model.parameters())\n","optimizer = AdaBelief(model.parameters(), lr=1e-3, eps=1e-16, betas=(0.9,0.999), weight_decouple = True, rectify = False)\n","scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n","#scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True)\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","model.to(device)\n","print(model)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[31mPlease check your arguments if you have upgraded adabelief-pytorch from version 0.0.5.\n","\u001b[31mModifications to default arguments:\n","\u001b[31m                           eps  weight_decouple    rectify\n","-----------------------  -----  -----------------  ---------\n","adabelief-pytorch=0.0.5  1e-08  False              False\n","Current version (0.1.0)  1e-16  True               True\n","\u001b[31mFor a complete table of recommended hyperparameters, see\n","\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n","\u001b[0m\n","Weight decoupling enabled in AdaBelief\n","PhonesModel(\n","  (fc1): Linear(in_features=1313, out_features=4096, bias=True)\n","  (bnorm1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (dp1): Dropout(p=0.1, inplace=False)\n","  (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n","  (bnorm2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (dp2): Dropout(p=0.1, inplace=False)\n","  (fc3): Linear(in_features=2048, out_features=1024, bias=True)\n","  (bnorm3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (dp3): Dropout(p=0.1, inplace=False)\n","  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n","  (bnorm4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (dp4): Dropout(p=0.1, inplace=False)\n","  (fc5): Linear(in_features=1024, out_features=512, bias=True)\n","  (bnorm5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (dp5): Dropout(p=0.1, inplace=False)\n","  (fc6): Linear(in_features=512, out_features=256, bias=True)\n","  (bnorm6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (dp6): Dropout(p=0.1, inplace=False)\n","  (fc7): Linear(in_features=256, out_features=346, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3A8TUY_S0JMn"},"source":["def train_epoch(model, train_loader, criterion, optimizer):\n","  model.train()\n","\n","  running_loss = 0.0\n","  total_predictions = 0.0\n","  correct_predictions = 0.0\n","  model.to(device)\n","  \n","  start_time = time.time()\n","  \n","  # Print Learning Rate\n","  \n","  for batch_idx, (data, target) in enumerate(train_loader):   \n","    optimizer.zero_grad()   # .backward() accumulates gradients\n","    data = data.to(device)\n","    target = target.to(device) # all data & model on same device\n","\n","    outputs = model(data)\n","    _, predicted = torch.max(outputs.data, 1)\n","    \n","    total_predictions += target.size(0)\n","    correct_predictions += (predicted == target).sum().item()\n","    \n","    loss = criterion(outputs, target)\n","    running_loss += loss.item()\n","\n","    loss.backward()\n","    optimizer.step()\n","  scheduler.step()\n","  end_time = time.time()\n","  \n","  running_loss /= len(train_loader)\n","  acc = (correct_predictions/total_predictions)*100.0\n","  print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n","  print('Training Accuracy: ', acc, '%')\n","  return running_loss,acc\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sx4ZbxDj0J5H"},"source":["def val_model(model, val_loader, criterion):\n","  with torch.no_grad():\n","    model.eval()\n","    model.to(device)\n","\n","    running_loss = 0.0\n","    total_predictions = 0.0\n","    correct_predictions = 0.0\n","\n","    for batch_idx, (data, target) in enumerate(val_loader):   \n","      data = data.to(device)\n","      target = target.to(device)\n","\n","      outputs = model(data)\n","\n","      _, predicted = torch.max(outputs.data, 1)\n","      total_predictions += target.size(0)\n","      correct_predictions += (predicted == target).sum().item()\n","\n","      loss = criterion(outputs, target).detach()\n","      running_loss += loss.item()\n","\n","\n","    running_loss /= len(val_loader)\n","    acc = (correct_predictions/total_predictions)*100.0\n","    print('Validation Loss: ', running_loss)\n","    print('Validation Accuracy: ', acc, '%')\n","    return running_loss, acc\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ILtJ7tY0NnR"},"source":["def test_model(model, test_loader):\n","  with torch.no_grad():\n","    model.eval()\n","    pred = []\n","\n","    for batch_idx, (data) in enumerate(test_loader):   \n","      data = data.to(device)\n","      outputs = model(data)\n","\n","      _, predicted = torch.max(outputs.data, 1)\n","      pred.append(predicted.cpu().numpy()[0])\n","\n","    return np.array(pred)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n1EsTpSt0Qo7","executionInfo":{"status":"ok","timestamp":1604558203150,"user_tz":-180,"elapsed":35433694,"user":{"displayName":"M M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTpe2wb6eeAb5oACw2uQos9tk5KOT_ogG8zrvJog=s64","userId":"00095342535920509079"}},"outputId":"d6728536-610f-4a42-9f39-eebbe7439ca2","colab":{"base_uri":"https://localhost:8080/"}},"source":["n_epochs = 5\n","Train_acc = []\n","Train_loss = []\n","Val_loss = []\n","Val_acc = []\n","# loading our existing model\n","load_path_model = 'C:/Users/malji/Google Drive/Colab Notebooks/trained_model/trained_model_newXYZ.pt'\n","model.load_state_dict(torch.load(load_path_model))\n","\n","for i in range(n_epochs):\n","  print('Epoch: ',i+1)\n","  print('LR: ', scheduler.get_lr())\n","  train_loss,acc = train_epoch(model, train_loader, criterion, optimizer)\n","  test_loss, test_acc = val_model(model, val_loader, criterion)\n","  Train_loss.append(train_loss)\n","  Train_acc.append(acc)\n","  Val_loss.append(test_loss)\n","  Val_acc.append(test_acc)\n","  print('='*20)\n","  #scheduler.step(test_acc)\n","  torch.save(model.state_dict(), 'C:/Users/malji/Google Drive/Colab Notebooks/trained_model/trained_model_newXYZ.pt')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch:  1\n","LR:  [0.000125]\n"],"name":"stdout"},{"output_type":"stream","text":["<ipython-input-13-38b4ca83bf3d>:38: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = F.log_softmax(self.fc7(x))\n"],"name":"stderr"},{"output_type":"stream","text":["Training Loss:  0.05980727315243796 Time:  1692.618938922882 s\n","Training Accuracy:  98.0459553006551 %\n","Validation Loss:  3.1243579111191457\n","Validation Accuracy:  56.57918773977042 %\n","====================\n","Epoch:  2\n","LR:  [0.00025]\n","Training Loss:  0.055534576328970416 Time:  1684.292457818985 s\n","Training Accuracy:  98.18641445752517 %\n","Validation Loss:  3.175539022880743\n","Validation Accuracy:  56.577811366838425 %\n","====================\n","Epoch:  3\n","LR:  [0.00025]\n","Training Loss:  0.05339658571299918 Time:  1680.5725538730621 s\n","Training Accuracy:  98.2547226048038 %\n","Validation Loss:  3.228102258306944\n","Validation Accuracy:  56.578311866086416 %\n","====================\n","Epoch:  4\n","LR:  [0.00025]\n","Training Loss:  0.05177729221489825 Time:  1680.6305301189423 s\n","Training Accuracy:  98.30889511317842 %\n","Validation Loss:  3.232001688703656\n","Validation Accuracy:  56.52619738188843 %\n","====================\n","Epoch:  5\n","LR:  [0.00025]\n","Training Loss:  0.050491574157773694 Time:  1684.9339249134064 s\n","Training Accuracy:  98.34499177911025 %\n","Validation Loss:  3.232496380753467\n","Validation Accuracy:  56.55447558940042 %\n","====================\n","Epoch:  6\n","LR:  [6.25e-05]\n","Training Loss:  0.04454925209376685 Time:  1684.0970509052277 s\n","Training Accuracy:  98.54113858169855 %\n","Validation Loss:  3.37762385947316\n","Validation Accuracy:  56.67565896982239 %\n","====================\n","Epoch:  7\n","LR:  [0.000125]\n","Training Loss:  0.042475065382273997 Time:  1681.453412771225 s\n","Training Accuracy:  98.60737716986819 %\n","Validation Loss:  3.378314906104798\n","Validation Accuracy:  56.79871922242437 %\n","====================\n","Epoch:  8\n","LR:  [0.000125]\n","Training Loss:  0.0414647256725156 Time:  1683.4766626358032 s\n","Training Accuracy:  98.64082869378952 %\n","Validation Loss:  3.4081526579386643\n","Validation Accuracy:  56.709818043498395 %\n","====================\n","Epoch:  9\n","LR:  [0.000125]\n","Training Loss:  0.04051424594550047 Time:  1682.1400637626648 s\n","Training Accuracy:  98.67337452108646 %\n","Validation Loss:  3.4606609318278907\n","Validation Accuracy:  56.72101671417239 %\n","====================\n","Epoch:  10\n","LR:  [0.000125]\n","Training Loss:  0.03989757230555416 Time:  1685.4349038600922 s\n","Training Accuracy:  98.69338449136733 %\n","Validation Loss:  3.4830950867554114\n","Validation Accuracy:  56.75580141190838 %\n","====================\n","Epoch:  11\n","LR:  [3.125e-05]\n","Training Loss:  0.03765095388759129 Time:  1683.2622718811035 s\n","Training Accuracy:  98.76322470489843 %\n","Validation Loss:  3.555145021764267\n","Validation Accuracy:  56.75761572168238 %\n","====================\n","Epoch:  12\n","LR:  [6.25e-05]\n","Training Loss:  0.03640772568925115 Time:  1683.3214483261108 s\n","Training Accuracy:  98.80279602937522 %\n","Validation Loss:  3.5462581676470974\n","Validation Accuracy:  56.76725033220637 %\n","====================\n","Epoch:  13\n","LR:  [6.25e-05]\n","Training Loss:  0.0358939364927492 Time:  1684.1911041736603 s\n","Training Accuracy:  98.81969954487899 %\n","Validation Loss:  3.4879627519697047\n","Validation Accuracy:  56.718451655526394 %\n","====================\n","Epoch:  14\n","LR:  [6.25e-05]\n","Training Loss:  0.035331611365393326 Time:  1684.770252943039 s\n","Training Accuracy:  98.83870224508226 %\n","Validation Loss:  3.529536327250507\n","Validation Accuracy:  56.770816389348376 %\n","====================\n","Epoch:  15\n","LR:  [6.25e-05]\n","Training Loss:  0.034968855188805166 Time:  1685.0894854068756 s\n","Training Accuracy:  98.84998113061495 %\n","Validation Loss:  3.5733907689638125\n","Validation Accuracy:  56.75173485551838 %\n","====================\n","Epoch:  16\n","LR:  [1.5625e-05]\n","Training Loss:  0.033796279300063875 Time:  1684.2000370025635 s\n","Training Accuracy:  98.8856841994156 %\n","Validation Loss:  3.5847243273930243\n","Validation Accuracy:  56.82487030813236 %\n","====================\n","Epoch:  17\n","LR:  [3.125e-05]\n","Training Loss:  0.03329391306208931 Time:  1684.6037600040436 s\n","Training Accuracy:  98.9037304162679 %\n","Validation Loss:  3.590348694838636\n","Validation Accuracy:  56.77732287957238 %\n","====================\n","Epoch:  18\n","LR:  [3.125e-05]\n","Training Loss:  0.033119901420505665 Time:  1682.9457867145538 s\n","Training Accuracy:  98.91121299398715 %\n","Validation Loss:  3.5530246494816407\n","Validation Accuracy:  56.89863138480634 %\n","====================\n","Epoch:  19\n","LR:  [3.125e-05]\n","Training Loss:  0.032792999236131895 Time:  1683.5568165779114 s\n","Training Accuracy:  98.92116719240099 %\n","Validation Loss:  3.571319322085663\n","Validation Accuracy:  56.870415739700356 %\n","====================\n","Epoch:  20\n","LR:  [3.125e-05]\n","Training Loss:  0.0325238541224386 Time:  1682.7210505008698 s\n","Training Accuracy:  98.93091401168121 %\n","Validation Loss:  3.5468452948072184\n","Validation Accuracy:  56.93160177276834 %\n","====================\n"],"name":"stdout"}]}]}